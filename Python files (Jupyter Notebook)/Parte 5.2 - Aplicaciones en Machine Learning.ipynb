{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b39c44d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.1 Cronología:\n",
    "\n",
    "# 1. Se estudia a nivel estadístico las características de las variables originales,\n",
    "#    Assurance y Matching. Se llega a la conlusión que Assurance al explicar directamente\n",
    "#    a Matching, que es prescindible para evitar redundancias.\n",
    "\n",
    "# 2. A nivel econométrico se pone a prueba el modelo original, lo cual dará indirectamente\n",
    "#    luz verde a la inclusión de Matching, ya que las variables en su conjunto son significativas.\n",
    "\n",
    "# 3. Finalmente para certificar si Matching es necesario y relevante en el modelo, se va a\n",
    "#    comparar los rendimientos de algoritmos kNN y de árboles de decisión.\n",
    "#    Esto servirá como confirmación final de qué modelo es el idóneo para predecir las contrataciones\n",
    "#    en función del perfil ofertado.\n",
    "\n",
    "# ATENCIÓN: en este caso se va a utilizar el fichero 6 que SÍ incluye la columna Matching, por\n",
    "#           lo que se va a poner a prueba el modelo mejorado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5cafc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Importamos todas las librerías que creemos útiles\n",
    "\n",
    "import io # Provee diferentes tipos de E/S: texto E/S, binario E/S e E/S.\n",
    "\n",
    "import os # Leer o escribir un archivo.\n",
    "\n",
    "import math # Proporciona acceso a las funciones matemáticas definidas en C.\n",
    "\n",
    "import csv # Para cargar y manejar CSV.\n",
    "\n",
    "import xlrd # Funcionalidades de excel en Python (1/2).\n",
    "\n",
    "import xlwt # Funcionalidades de excel en Python (2/2).\n",
    "\n",
    "import sklearn # Funcionalidades de Machine Learning.\n",
    "\n",
    "import numpy as np # Manejo de datos extremadamente rápido cálculo numérico.\n",
    "\n",
    "import scipy as sp # Módulos para optimización, álgebra lineal, etc.\n",
    "\n",
    "import pandas as pd # Módulos de gestión de ficheros y dataframes.\n",
    "\n",
    "import matplotlib.pyplot as plt # Generación de gráficos.\n",
    "\n",
    "import statsmodels.api as sm # Módulo estadístico.\n",
    "\n",
    "import random # Para fijar resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50691a3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Education</th>\n",
       "      <th>Work Exp</th>\n",
       "      <th>Programming Exp</th>\n",
       "      <th>Matching</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>829 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Gender  Education  Work Exp  Programming Exp  Matching  Status\n",
       "0         0          1         0                0         0       0\n",
       "1         1          1         0                1         1       1\n",
       "2         1          1         1                0         1       1\n",
       "3         1          1         0                0         0       0\n",
       "4         1          0         1                0         0       1\n",
       "..      ...        ...       ...              ...       ...     ...\n",
       "824       1          1         0                0         1       1\n",
       "825       1          1         1                0         1       1\n",
       "826       1          1         0                1         0       0\n",
       "827       1          1         0                0         1       1\n",
       "828       1          1         1                0         1       1\n",
       "\n",
       "[829 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Cargamos y leemos el fichero6.\n",
    "\n",
    "fichero6 = pd.read_csv(r'C:\\Users\\jlc15\\Desktop\\MECOFIN\\2º Cuatrimestre\\TFM\\Y - Ficheros Python\\fichero6.csv')\n",
    "\n",
    "fichero6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08ba205c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Algoritmos de clasificación con kNN:\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "11fa361a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión: 0.7932692307692307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "# 3.1.1 Intento 1: kNN predeterminado con la distancia de Euclídea.\n",
    "\n",
    "# La distancia euclidiana es una métrica de distancia que se utiliza para datos continuos.\n",
    "\n",
    "x = fichero6.iloc[:, :-1] # Seleccionamos todas las columnas excepto la última\n",
    "\n",
    "y = fichero6.iloc[:, -1] # Elegimos sólo la última columna\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=300) # Ajustamos el parámetro 'k'.\n",
    "\n",
    "knn.fit(x_train, y_train)\n",
    "\n",
    "y_pred = knn.predict(x_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f'Precisión: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0df8d715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[259   0]\n",
      " [  0 570]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "# 3.1.2 Intento 1: matriz de confusión.\n",
    "\n",
    "x = fichero6.iloc[:, :6]\n",
    "\n",
    "y = fichero6['Status']\n",
    "\n",
    "# Escogemos k=8 porque es el óptimo.\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=8)\n",
    "\n",
    "knn.fit(x, y)\n",
    "\n",
    "y_pred = knn.predict(x)\n",
    "\n",
    "confm = confusion_matrix(y, y_pred)\n",
    "\n",
    "print(confm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30b0f4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1.3 Intento 1: resultados del kNN según parámetro 'k'.\n",
    "\n",
    "# Intento 1: k = 2 --> 89.90%.\n",
    "\n",
    "# Intento 2: k = 4 --> 90.86%.\n",
    "\n",
    "# Intento 3: k = 6 --> 94.71%. Máximo.\n",
    "\n",
    "# Intento 4: k = 8 --> 94.71%. Óptimo.\n",
    "\n",
    "# Intento 5: k = 10 --> 93.75%.\n",
    "\n",
    "# Intento 6: k = 20 --> 93.75%.\n",
    "\n",
    "# Intento 7: k = 40 --> 92.30%.\n",
    "\n",
    "# Intento 8: k = 80 --> 88.46%.\n",
    "\n",
    "# Intento 9: k = 150 --> 85.09%.\n",
    "\n",
    "# Intento 10: k = 300 --> 79.32%. Mínimo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "df2b6f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión: 0.7115384615384616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "# 3.2.1 Intento 2: kNN con la distancia de Jaccard.\n",
    "\n",
    "# Jaccard es una métrica de distancia que se utiliza para datos binarios o categóricos.\n",
    "\n",
    "x = fichero6.iloc[:, :-1]\n",
    "\n",
    "y = fichero6.iloc[:, -1]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=300, metric='jaccard')\n",
    "\n",
    "knn.fit(x_train, y_train)\n",
    "\n",
    "y_pred = knn.predict(x_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f'Precisión: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3fb641d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[259   0]\n",
      " [  0 570]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "# 3.2.2 Intento 2: matriz de confusión.\n",
    "\n",
    "x = fichero6.iloc[:, :6]\n",
    "\n",
    "y = fichero6['Status']\n",
    "\n",
    "# Escogemos k=6 porque es el óptimo.\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=6)\n",
    "\n",
    "knn.fit(x, y)\n",
    "\n",
    "y_pred = knn.predict(x)\n",
    "\n",
    "confm = confusion_matrix(y, y_pred)\n",
    "\n",
    "print(confm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fcbdf82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2.3 Intento 2: resultados del kNN según parámetro 'k'.\n",
    "\n",
    "# Intento 1: k = 2 --> 91.82%.\n",
    "\n",
    "# Intento 2: k = 4 --> 93.26%. Máximo.\n",
    "\n",
    "# Intento 3: k = 6 --> 93.26%. Óptimo.\n",
    "\n",
    "# Intento 4: k = 8 --> 91.82%.\n",
    "\n",
    "# Intento 5: k = 10 --> 88.46%.\n",
    "\n",
    "# Intento 6: k = 20 --> 93.26%.\n",
    "\n",
    "# Intento 7: k = 40 --> 92.78%.\n",
    "\n",
    "# Intento 8: k = 80 --> 78.84%.\n",
    "\n",
    "# Intento 9: k = 150 --> 78.84%.\n",
    "\n",
    "# Intento 10: k = 300 --> 71.15%. Mínimo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8073ab5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión: 0.7211538461538461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "# 3.3.1 Intento 3: kNN con la distancia de Hamming.\n",
    "\n",
    "# Hamming es una métrica de distancia discreta que se utiliza para datos binarios.\n",
    "\n",
    "x = fichero6.iloc[:, :-1] \n",
    "\n",
    "y = fichero6.iloc[:, -1] \n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=300, metric='hamming')\n",
    "\n",
    "knn.fit(x_train, y_train)\n",
    "\n",
    "y_pred = knn.predict(x_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f'Precisión: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d27bc077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[259   0]\n",
      " [  0 570]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "# 3.3.2 Intento 3: matriz de confusión.\n",
    "\n",
    "x = fichero6.iloc[:, :6]\n",
    "\n",
    "y = fichero6['Status']\n",
    "\n",
    "# Escogemos k=6 porque es el óptimo.\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=6)\n",
    "\n",
    "knn.fit(x, y)\n",
    "\n",
    "y_pred = knn.predict(x)\n",
    "\n",
    "confm = confusion_matrix(y, y_pred)\n",
    "\n",
    "print(confm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a2c85a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.3.3 Intento 3: resultados del kNN según parámetro 'k'.\n",
    "\n",
    "# Intento 1: k = 2 --> 92.30%.\n",
    "\n",
    "# Intento 2: k = 4 --> 92.78%. Máximo.\n",
    "\n",
    "# Intento 3: k = 6 --> 92.78%. Óptimo.\n",
    "\n",
    "# Intento 4: k = 8 --> 88.94%.\n",
    "\n",
    "# Intento 5: k = 10 --> 91.82%.\n",
    "\n",
    "# Intento 6: k = 20 --> 92.30%.\n",
    "\n",
    "# Intento 7: k = 40 --> 92.78%.\n",
    "\n",
    "# Intento 8: k = 80 --> 92.78%.\n",
    "\n",
    "# Intento 9: k = 150 --> 81.25%.\n",
    "\n",
    "# Intento 10: k = 300 --> 72.11%. Mínimo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "825ab859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.3 Conclusiones de los resultados.\n",
    "\n",
    "# a) En primer lugar no podemos descartar que el dataset sea sensible al ruido y\n",
    "#    al sobreajuste, ya que el 'k' seleccionado es algo reducido. Sin embargo,\n",
    "#    hay un amplio rango inicial de 'k' que tiene una precisión muy parecida, por\n",
    "#    lo que tampoco se puede afirmar que tenga sensibilidad al ruido ni sobreajuste.\n",
    "\n",
    "# b) Por otro lado, los 'k' más grandes tampoco dan la máxima precisión,\n",
    "#    evitando así, un subajuste.\n",
    "\n",
    "# c) Por ende, el 'k' óptimo aproximadamente será entre k=6 y k=8. Consideramos que  \n",
    "#    es un valor razonable, ya que no está cerca del mínimo (k=1) ni supone \n",
    "#    un 'k' enorme que de un resultado similar (k=40).\n",
    "\n",
    "# d) La matriz de confusión es excelente ya que no refleja falsos positivos\n",
    "#    ni falsos negativos.\n",
    "\n",
    "# e) Se debe tener en cuenta, de nuevo, que al reiniciar el Kernel y ejecutarlo todo\n",
    "#    de nuevo los resultados del KNN no tienen por qué ser exactamente el\n",
    "#    mismo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85ff897d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.4 Otros posibles intentos.\n",
    "\n",
    "# Algunas ditancias que se pueden aplizar también son: Manhattan, Chebyshev y Mahalanobis.\n",
    "\n",
    "# Sin embargo, se ha optado por la Euclídea por ser la predeterminada, la Jaccard y la\n",
    "# Hamming por estar orientadas a datos binarios. \n",
    "\n",
    "# Por otro lado, el resto de distancias:\n",
    "\n",
    "# Manhattan es una métrica de distancia que se utiliza para datos continuos.\n",
    "\n",
    "# Chebyshev es una métrica de distancia que se utiliza para datos continuos.\n",
    "\n",
    "# Mahalanobis es una métrica de distancia que se utiliza para datos multivariados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6df28e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Algoritimos de clasificación y regresión con árboles de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e3db4f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión: 0.9423076923076923\n"
     ]
    }
   ],
   "source": [
    "# 4.1.1 Clasificación.\n",
    "\n",
    "# Los valores predeterminados para los parámetros que controlan el tamaño \n",
    "# y el número de hojas en el algoritmo de clasificación de árboles de \n",
    "# decisión de scikit-learn conducen a árboles sin podar.\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "x = fichero6.iloc[:, :-1]\n",
    "\n",
    "y = fichero6.iloc[:, -1]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25)\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f'Precisión: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "de85edbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 55   5]\n",
      " [  7 141]]\n"
     ]
    }
   ],
   "source": [
    "# 4.1.2 Matriz de confusión.\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4e9c840e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Cuadrático Medio: 0.03897959828264581\n",
      "Raíz del ECM: 0.19743251576841594\n",
      "Rango de la vble endógena: 1\n"
     ]
    }
   ],
   "source": [
    "# 4.2.1 Regresión.\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "x = fichero6.iloc[:, :-1] \n",
    "\n",
    "y = fichero6.iloc[:, -1] \n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25)\n",
    "\n",
    "reg = DecisionTreeRegressor()\n",
    "\n",
    "reg.fit(x_train, y_train)\n",
    "\n",
    "y_pred = reg.predict(x_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "y_range = y.max() - y.min()\n",
    "\n",
    "print(f'Error Cuadrático Medio: {mse}')\n",
    "\n",
    "print(f'Raíz del ECM: {rmse}')\n",
    "\n",
    "print(f'Rango de la vble endógena: {y_range}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1eb7df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.3 Conclusiones:\n",
    "\n",
    "# a) La precisión del modelo según el test ha sido de un 94.23%, un resultado\n",
    "#    similar a los kNN.\n",
    "\n",
    "# b) El ECM es de 0.038. Por sí mismo no posee valor o interpretación absoluta,\n",
    "#    pero lo que sí sabemos es que cuanto más cerca del valor cero, mejor.\n",
    "\n",
    "# c) Por otro lado, el rango de valores de la variable endógena es 1, lo que \n",
    "#    significa que la diferencia entre el valor máximo y mínimo de la variable \n",
    "#    dependiente es 1 unidad. En este caso, la raíz del ECM es aproximadamente \n",
    "#    un 19.74% del rango de valores. Esto sugiere que las predicciones del \n",
    "#    modelo son bastante precisas.\n",
    "\n",
    "# d) La matriz de confusión proviene del 25% de 829 que es 208. Por otra parte, \n",
    "#    apenas posee falsos positivos y falsos negativos, lo cual es un signo positivo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
